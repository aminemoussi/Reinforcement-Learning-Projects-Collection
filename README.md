# Reinforcement Learning Projects Collection (will be uploaded soon, almost finished)

A collection of reinforcement learning implementations showcasing fundamental to advanced algorithms. Perfect for understanding RL concepts and their practical applications in autonomous systems and decision-making.

ğŸ“‹ Repository Structure

```
RL-Projects/
â”œâ”€â”€ 1-Q-Learning-GridWorld/
â”‚   â”œâ”€â”€ qlearning_gridworld.ipynb
â”‚   â”œâ”€â”€ media/
â”‚   â”‚   â”œâ”€â”€ qgame_1.png
â”‚   â”‚   â”œâ”€â”€ qgame_2.png
â”‚   â”‚   â””â”€â”€ qtable.png
â”‚   â””â”€â”€ README.md
â”œâ”€â”€ 2-DeepQ-Network-CartPole/
â”‚   â”œâ”€â”€ dqn_cartpole.ipynb
â”‚   â”œâ”€â”€ cartpole_model/
â”‚   â”‚   â””â”€â”€ DQN.keras
â”‚   â”œâ”€â”€ media/
â”‚   â”‚   â”œâ”€â”€ cart_pole.gif
â”‚   â”‚   â”œâ”€â”€ DQN_policy_viz.png
â”‚   â”‚   â””â”€â”€ dqn_net.png
â”‚   â””â”€â”€ README.md
â”œâ”€â”€ 3-PPO-Pong/
â”‚   â”œâ”€â”€ ppo_pong.ipynb
â”‚   â”œâ”€â”€ ppo_models/
â”‚   â”‚   â”œâ”€â”€ pong_ppo_early.zip
â”‚   â”‚   â””â”€â”€ pong_ppo_best.zip
â”‚   â”œâ”€â”€ media/
â”‚   â”‚   â”œâ”€â”€ ponggif.gif
â”‚   â”‚   â”œâ”€â”€ ppo_model_arch.png
â”‚   â”‚   â”œâ”€â”€ action_prob_ppo.png
â”‚   â”‚   â””â”€â”€ preprocessing.png
â”‚   â””â”€â”€ README.md
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md (main repository README)
```

# ğŸ“ Projects Overview
## 1. ğŸ¤– Q-Learning: Grid World Navigation

This implementation demonstrates classic Q-Learning in a 4x4 grid environment with obstacles. The agent starts at (0,0) and learns to navigate to the goal at (3,3) while avoiding obstacles.

Key Features:
- Tabular Q-learning implementation
- Dynamic exploration-exploitation balance (Îµ-greedy)
- Optimal policy visualization
- Custom grid environment with obstacles

Results:
 - Learned Policy: ![](Q-learning/media/policy.png)
 - Training Progress: ![](Classic_CNN/media/training_progress.png)
 - Training Progress: ![](Classic_CNN/media/training_progress.png)

---------

## 2. ğŸ§  Deep Q-Network: CartPole Balancing
Screenshot: media/DQN_policy_viz.png

Key Features:
- Neural network Q-value approximation
- Experience replay buffer
- Target network stabilization
- Double DQN implementation

Architecture:
Input (4) â†’ Dense(24) â†’ Dense(24) â†’ Output(2)
Total Parameters: 770

Performance: Achieved perfect score of 500/500 consistently

## 3. ğŸ® Proximal Policy Optimization: Atari Pong
Screenshot: media/action_prob_ppo.png

Key Features:
- Policy gradient optimization with clipping
- Convolutional neural network for pixel input
- Frame stacking and preprocessing
- Advantage estimation using GAE

Model Architecture:
- Input: 84x84x4 stacked frames
- CNN Backbone: 3 convolutional layers
- Heads: Actor (policy) + Critic (value)
- Training: 0M timesteps with stable learning

## ğŸ› ï¸ Installation
```
git clone https://github.com/yourusername/RL-Projects.git
cd RL-Projects
```

## Install dependencies
```
pip install -r requirements.txt
```

requirements.txt:
```
gymnasium==0.29.1
tensorflow==2.15.0
stable-baselines3==2.0.0
numpy==1.24.3
ale-py==0.9.0
opencv-python==4.8.1
wandb==0.16.1
```


## ğŸ“Š Algorithm Comparison
Algorithm	Type	State Space	Action Space	Best For
Q-Learning	Value-based	Discrete	Discrete	Small, tabular environments
DQN	Value-based	Continuous	Discrete	High-dimensional observations
PPO	Policy-based	Continuous	Discrete/Continuous	Complex, stochastic environments
